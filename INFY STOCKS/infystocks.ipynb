{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh\\AppData\\Local\\Temp\\ipykernel_21988\\3868498806.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.48\n",
      "Logistic Regression cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.48      1.00      0.65        24\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.24      0.50      0.32        50\n",
      "weighted avg       0.23      0.48      0.31        50\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "Decision Tree cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "Gradient Boosting Accuracy: 1.0\n",
      "Gradient Boosting cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "KNN Accuracy: 0.52\n",
      "KNN cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56        26\n",
      "           1       0.50      0.46      0.48        24\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.52      0.52      0.52        50\n",
      "weighted avg       0.52      0.52      0.52        50\n",
      "\n",
      "SVM Accuracy: 0.66\n",
      "SVM cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64        26\n",
      "           1       0.62      0.75      0.68        24\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.67      0.66      0.66        50\n",
      "weighted avg       0.67      0.66      0.66        50\n",
      "\n",
      "Neural Network Accuracy: 0.52\n",
      "Neural Network cpr:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        26\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.26      0.50      0.34        50\n",
      "weighted avg       0.27      0.52      0.36        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load Infosys stock data\n",
    "infy_data = pd.read_csv('infy_stock_data.csv')  # Replace 'infy_stock_data.csv' with your file path\n",
    "\n",
    "# Handle missing values if any\n",
    "infy_data = infy_data.dropna()  # Drop rows with missing values\n",
    "infy_data = pd.get_dummies(infy_data, columns=['Symbol','Series'])\n",
    "\n",
    "# Feature engineering (if needed)\n",
    "\n",
    "# Assuming 'Close' is the target variable, convert it to categorical for classification\n",
    "infy_data['Close'] = pd.qcut(infy_data['Close'], q=2, labels=False)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = infy_data.drop(columns=['Date', 'Close'])  # Assuming 'Close' is the target variable\n",
    "y = infy_data['Close']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_cpr = classification_report(y_test, lr_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression cpr:\", lr_cpr)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_cpr = classification_report(y_test, dt_predictions)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Decision Tree cpr:\", dt_cpr)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_cpr = classification_report(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest cpr:\", rf_cpr)\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "gb_cpr = classification_report(y_test, gb_predictions)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "print(\"Gradient Boosting cpr:\", gb_cpr)\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_cpr = classification_report(y_test, knn_predictions)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n",
    "print(\"KNN cpr:\", knn_cpr)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_cpr = classification_report(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM cpr:\", svm_cpr)\n",
    "# Neural Network\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_predictions = nn_model.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
    "nn_cpr = classification_report(y_test, nn_predictions)\n",
    "print(\"Neural Network Accuracy:\", nn_accuracy)\n",
    "print(\"Neural Network cpr:\", nn_cpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
