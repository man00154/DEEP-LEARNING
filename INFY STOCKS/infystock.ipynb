{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error: 8.24082968259905\n",
      "Linear Regression MAE: 2.1121992682297015\n",
      "Linear Regression r2: 0.9999722088060895\n",
      "Lasso Regression Mean Squared Error: 286.65047431509157\n",
      "Lasso Regression MAE: 10.65226819685103\n",
      "Lasso Regression r2: 0.9990333062054343\n",
      "Ridge Regression Mean Squared Error: 8.263350552644347\n",
      "Ridge Regression MAE: 2.1194586846827543\n",
      "Ridge Regression r2: 0.9999721328571995\n",
      "Decision Tree Mean Squared Error: 52.996450000000394\n",
      "Decision Tree MAE: 5.30500000000005\n",
      "Decision Tree r2: 0.999821275930307\n",
      "Random Forest Mean Squared Error: 62.05785397499755\n",
      "Random Forest MAE: 5.188649999999914\n",
      "Random Forest r2: 0.9997907174495873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+04, tolerance: 5.441e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Deep Learnig 6_8 PM Thu Fri\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.5185e-33): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Mean Squared Error: 44.36378582073611\n",
      "Gradient Boosting MAE: 4.665387125316888\n",
      "Gradient Boosting r2: 0.9998503885383102\n",
      "KNN Mean Squared Error: 303497.56328799995\n",
      "KNN MAE: 500.03439999999995\n",
      "KNN r2: -0.023508549209097174\n",
      "SVM Mean Squared Error: 462987.8899882068\n",
      "SVM MAE: 486.9583511769565\n",
      "SVM r2: -0.5613702411624835\n",
      "Neural Network Mean Squared Error: 2.5120678657177596e+24\n",
      "Neural Network MAE: 1286661455966.8123\n",
      "Neural Network r2: -8.471642766751787e+18\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load Infosys stock data\n",
    "infy_data = pd.read_csv('infy_stock_data.csv')  # Replace 'infy_stock_data.csv' with your file path\n",
    "\n",
    "# Handle missing values if any\n",
    "infy_data = infy_data.dropna()  # Drop rows with missing values\n",
    "infy_data = pd.get_dummies(infy_data, columns=['Symbol','Series']) \n",
    "\n",
    "# Feature engineering (if needed)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = infy_data.drop(columns=['Date', 'Close'])  # Assuming 'Close' is the target variable\n",
    "y = infy_data['Close']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression MAE:\", lr_mae)\n",
    "print(\"Linear Regression r2:\", lr_r2)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_predictions)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "\n",
    "print(\"Lasso Regression Mean Squared Error:\", lasso_mse)\n",
    "print(\"Lasso Regression MAE:\", lasso_mae)\n",
    "print(\"Lasso Regression r2:\", lasso_r2)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_predictions)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_predictions)\n",
    "ridge_r2 = r2_score(y_test, ridge_predictions)\n",
    "\n",
    "print(\"Ridge Regression Mean Squared Error:\", ridge_mse)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae)\n",
    "print(\"Ridge Regression r2:\", ridge_r2)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "print(\"Decision Tree Mean Squared Error:\", dt_mse)\n",
    "print(\"Decision Tree MAE:\", dt_mae)\n",
    "print(\"Decision Tree r2:\", dt_r2)\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest MAE:\", rf_mae)\n",
    "print(\"Random Forest r2:\", rf_r2)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(\"Gradient Boosting Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting MAE:\", gb_mae)\n",
    "print(\"Gradient Boosting r2:\", gb_r2)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_mse = mean_squared_error(y_test, knn_predictions)\n",
    "knn_mae = mean_absolute_error(y_test, knn_predictions)\n",
    "knn_r2 = r2_score(y_test, knn_predictions)\n",
    "\n",
    "\n",
    "print(\"KNN Mean Squared Error:\", knn_mse)\n",
    "print(\"KNN MAE:\", knn_mae)\n",
    "print(\"KNN r2:\", knn_r2)\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "svm_mae = mean_absolute_error(y_test, svm_predictions)\n",
    "svm_r2 = r2_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Mean Squared Error:\", svm_mse)\n",
    "print(\"SVM MAE:\", svm_mae)\n",
    "print(\"SVM r2:\", svm_r2)\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_predictions = nn_model.predict(X_test)\n",
    "nn_mse = mean_squared_error(y_test, nn_predictions)\n",
    "nn_mae = mean_absolute_error(y_test, nn_predictions)\n",
    "nn_r2 = r2_score(y_test, nn_predictions)\n",
    "\n",
    "\n",
    "print(\"Neural Network Mean Squared Error:\", nn_mse)\n",
    "print(\"Neural Network MAE:\", nn_mae)\n",
    "print(\"Neural Network r2:\", nn_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
